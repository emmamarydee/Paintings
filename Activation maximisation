import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import os

#ResNet101 model initialisation
model = models.resnet101(pretrained=True)

# Freeze all layers
for param in model.parameters():
    param.requires_grad = False

# Unfreeze from layer4.1 onward
for name, module in model.named_modules():
    if "layer4.1" in name or "layer4.2" in name:
        for param in module.parameters():
            param.requires_grad = True

# Replace classifier
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

#Train the model 
params_to_update = [p for p in model.parameters() if p.requires_grad]
optimizer = optim.Adam(params_to_update, lr=1e-4, weight_decay=1e-5)
criterion = nn.CrossEntropyLoss()

#Training loop
def train(model, train_loader, val_loader, epochs=10):
    for epoch in range(epochs):
        model.train()
        total_loss = 0.0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            output = model(images)
            loss = criterion(output, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch {epoch+1}: Train Loss = {total_loss / len(train_loader)}")

        # Validation
        model.eval()
        correct, total = 0, 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                output = model(images)
                preds = output.argmax(dim=1)
                correct += (preds == labels).sum().item()
                total += labels.size(0)

        acc = correct / total

# Train model
train(model, train_loader, val_loader, epochs=10)


################################### Activation maximisation ###################################
class NormalisedModel(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model.eval()
        self.mean = torch.tensor(mean)[:, None, None]
        self.std = torch.tensor(std)[:, None, None]

    def forward(self, x):
        return self.model((x - self.mean.to(x.device)) / self.std.to(x.device))

def total_variation(x):
    return torch.abs(x[:, :, :-1, :] - x[:, :, 1:, :]).mean() + \
           torch.abs(x[:, :, :, :-1] - x[:, :, :, 1:]).mean()

def gaussian_blur(x, kernel_size=3, sigma=1):
    if kernel_size % 2 == 0:
        kernel_size += 1
    channels = x.shape[1]
    kernel_1d = torch.linspace(-sigma, sigma, steps=kernel_size)
    pdf = torch.exp(-0.5 * (kernel_1d / sigma)**2)
    pdf /= pdf.sum()
    kernel = pdf[:, None] @ pdf[None, :]
    kernel = kernel.expand(channels, 1, -1, -1).to(x.device)
    return F.conv2d(x, kernel, padding=kernel_size // 2, groups=channels)

def maximise_class(model, class_index, img_size=224, steps=1000,
                   lr=0.07, tv_weight=2e-5, l2_weight=1e-6,
                   jitter=8, blur_every=5, blur_kernel=3):
    model = NormalisedModel(model).to(device)
    img = torch.rand(1, 3, img_size, img_size, device=device, requires_grad=True)
    optimizer = optim.Adam([img], lr=lr)

    for step in range(steps):
        optimizer.zero_grad()
        shift = tuple(torch.randint(-jitter, jitter + 1, (2,)).tolist())
        jittered = torch.roll(img, shifts=shift, dims=(-2, -1))

        output = model(jittered)
        loss = -output[0, class_index] + tv_weight * total_variation(img) + l2_weight * torch.norm(img)
        loss.backward()

        if step % blur_every == 0 and img.grad is not None:
            with torch.no_grad():
                img.grad = gaussian_blur(img.grad, kernel_size=blur_kernel)

        optimizer.step()
        img.data.clamp_(0, 1)

    return img.detach().cpu().squeeze()

def show_image(img_tensor):
    img = img_tensor.permute(1, 2, 0).numpy()
    img = (img - img.min()) / (img.max() - img.min())
    plt.imshow(img)
    plt.axis("off")
    plt.show()

#Plot for each artist
fig, axes = plt.subplots(2, 5, figsize=(20, 8))

for i in range(10):
    img = maximise_class(model, i, steps=1500)

    img = img.detach().cpu().permute(1, 2, 0).numpy()
    img = (img - img.min()) / (img.max() - img.min())

    ax = axes[i // 5][i % 5]
    ax.imshow(img)
    ax.set_title(class_names[i], fontsize=14)
    ax.axis("off")

plt.tight_layout()
plt.show()


#Function to indentify the top k=5 activated channels in a convolutional layer for each class
def top_k_channels(model, loader, layer_name, class_index, k=5):
    model.eval()
    device = next(model.parameters()).device
    activations = []

    def hook_fn(_, __, output):
        activations.append(output.detach().cpu())

    handle = dict(model.named_modules())[layer_name].register_forward_hook(hook_fn)

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            mask = labels == class_index
            if mask.sum() == 0:
                continue
            images = images[mask]
            _ = model(images)
            break 

    handle.remove()
    A = torch.cat(activations, dim=0)  # [B, C, H, W]
    mean_activations = A.mean(dim=[0, 2, 3])  # [C]
    topk = mean_activations.topk(k=k).indices.tolist()
    return topk
